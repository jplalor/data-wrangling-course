---
title: "Data Wrangling With R: Day Three"
author: "Prof. John Lalor"
output:
  html_document:
    toc: true
    toc_float: true
    theme: flatly
    highlight: zenburn
    css: documentCSS.css
---


```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, error = FALSE, comment = "")
```

# Admin
## Day 2 Follow-up

### Corrplot Details 

> Is the size of the corrplot dot meaningful?

Yes. From the corrplot vignette (https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html):

> Positive correlations are displayed in blue and negative correlations in red color. Color intensity and the size of the circle are proportional to the correlation coefficients.

```{r}
library(corrplot)
library(dplyr)
testData <- haven::read_dta(file = "https://www3.nd.edu/~sberry5/data/stataExample.dta")

testData %>%
  select(starts_with("lvi0")) %>%
  cor(., use="pairwise.complete.obs") %>% 
  corrplot()

```

### Regex and Contractions

> What's the deal with Can't from yesterday's examples?

```{r}

library(stringr)

realComments = c("I love wrangling data", "strings r fun", 
                 "I wish it were break", "Can't we use excel?")

str_subset(string = realComments, pattern = "\\b[a-z]{4}\\b")

# this catches the 4th example because of how word boundaries are defined
str_subset(string = realComments, pattern = "\\b[A-Za-z']{4}\\b")

# a better way to find 4 letter words (including contractions) 
str_subset(string=realComments, pattern = "\\b([A-Za-z]{4}|[A-Za-z]{3}'[A-Za-z])\\b")

# slightly more generic
realComments = c("I love wrangling data", "strings r fun", 
                 "Can't this be a little easier", "We're struggling here")

str_subset(string=realComments, pattern = "\\b([a-z]{4}|[a-z']{4}[a-z])\\b")
```


## Plan for the next two days

# Merging 

Having multiple datasets in memory is one of R's strong points (not everything can manage such a modern feat). 
Once you get out there, this becomes important.

Not only can we have multiple datasets open, but we can also merge those datasets together, with the proper variables, of course. 

## base

The <span class="func"></span>merge function in base R, like everything else, can do us a great amount of good. 

```{r, eval = FALSE}

board = haven::read_sas()

organization = haven::read_sas()

mergedDat = merge(x = board, y = organization, by = "", 
      all.x = TRUE, all.y = FALSE)

```

If there is anything good to be gotten from SQL, it is the notion of different joins and the handy language that it provides for specifying those joins. The merge function gives us no such explicit conventions (we would need to intuit or...read the documentation).


### Join Types

Left join = all rows from x and all columns from x and y

Right join = all rows from y and all columns from x and y

Inner join = all rows from x with matching values in y and all columns from x and y

Semi join = all rows from x with matching values in y and just columns from x

Full join = everything

With that knowledge, can we map the various combinations of all.x and all.y? 

## Left

```{r, eval = FALSE}
merge1 = haven::read_dta("https://www3.nd.edu/~sberry5/data/merge1Company.dta")

sasExample = haven::read_sas("https://www3.nd.edu/~sberry5/data/wciklink_gvkey.sas7bdat")

leftTest = left_join(merge1, sasExample, by = "gvkey")
```


If we want to join on multiple columns, we could provide a character vector:

```{r, eval = FALSE}
leftTestMultiple = left_join(merge1, sasExample, by = c("gvkey", "coname"))
```


If our names don't match, we need to provide both:

```{r, eval = FALSE}
leftTestEqual = left_join(merge1, sasExample, by = c("gvkey", 
                                                "coname", 
                                                "datadate" = "DATADATE1"))
```

How did this one work? 
Always check your data!

## Right

```{r, eval = FALSE}
rightTest = right_join(merge1, sasExample, by = c("gvkey"))
```

## Inner

```{r, eval = FALSE}
innerTest = inner_join(merge1, sasExample, by = c("gvkey"))
```


## Semi

```{r, eval = FALSE}
semiTest = semi_join(merge1, sasExample, by = c("gvkey"))
```


## Full

```{r, eval = FALSE}
fullTest = full_join(merge1, sasExample, by = c("gvkey"))
```


## Anti

I didn't mention the anti join before! It does exactly what it sounds like -- it finds the things that don't match. A natural curiousity is the potential purpose for such a function. Can anyone think of anything?

```{r, eval = FALSE}
antiTest = anti_join(merge1, sasExample, by = c("gvkey"))
```

## Your Turn! (YT5)

Let's look at these three files:

```{r, eval = FALSE}
merge1 = "https://www3.nd.edu/~sberry5/data/merge1Company.dta"

merge2Hoberg = "https://www3.nd.edu/~sberry5/data/merge2Hoberg.txt"

sasExample = "https://www3.nd.edu/~sberry5/data/wciklink_gvkey.sas7bdat"

```

1.  Read those files in appropriately (look at the file extensions...or rio).
2.  Start merging them together in any way that you can.

Chained merges look like this:

```{r, eval = FALSE}

## DO NOT RUN:

left_join(data1, data2, by = "id") %>% 
  left_join(., data3, by = "id") %>% 
  left_join(., data4, by = "id")

```



## Binding

On many occasions, you will want to bring data together in a "stacked" manner.

Imagine you have two data files that look exactly alike with regard to column names, but the values are different. This is when we could use a row bind:

```{r, eval = FALSE}
data2003 = read.csv("https://www3.nd.edu/~sberry5/data/c2003_a.csv")

data2004 = read.csv("https://www3.nd.edu/~sberry5/data/c2004_a.csv")

complete = rbind(data2003, data2004)

```


What if our rows were the same, but we wanted to add some columns? You said cbind, no doubt!

## Data Wrangling?

This is a point where we should revisit the term data wrangling. It makes sense conceptually, but it casts a certain mental image that might be limiting. What we have seen up to this point should make it abundantly clear that we are in control of our data -- this sits nicely with wrangling. What might not be so clear is the artistically forceful way that we sometimes need to make our data behave. Instead, we might want to think of ourselves as *Data Picassos*. Data preparation is often done through a series of data deconstructions -- much like making a collage. We take bits and pieces from various places and then put them together to make something coherent. This also sits nicely with out previous discussion on code golf.

Therefore, we need to learn to accept a default frame of reference that allows us to break things down into smaller pieces. We are not bound to any monolith. 


![](http://www.muralmosaic.com/Cochrane/grid.jpg)

Keep this concept of *data collaging* in your mind.



# Day 3 Intro
From what we've covered so far, you should be in a good position to wrangle a lot of different types of data. 
The tools from Days 1 and 2 will get you very far. 
Today we'll look at some interesting things for specific types of data, then wrap back around to some more common R techniques, and wrap up with preparation for tomorrow's hackathon. 
We'll be making teams and (starting to) select data sets for tomorrow at the end of today's class, so start thinking about potential teammates (3-5 students per team), team names, and data set ideas.


# Fuzzy Joins 

We have seen joins and some character work, but now we are going to combine them into one world.

Whenever we use joins we are generally looking for exact matches. 
In reality, we get about 50/50.

Fuzzy joins allow us to use string distance metrics to join non-matching strings together.

We are going to need <span class="pack">fuzzyjoin</span>:

```{r, eval = FALSE}
install.packages('devtools')

devtools::install_github("dgrtwo/fuzzyjoin")
```


## String Distances

Not including spelling mistakes, there are many different ways to represent words; this is especially true when we are discussing companies.

Would AG Edwards and A.G. Edwards join? 
Of course not! 
They are the same company, but not the same words.

We have learned enough about string cleaning to know that we could tidy that one up, but what about something more subtle, like AG Edward and AG Edwards. 

We can use the <span class="func">adist</span> function to figure out the distance between these two strings.

```{r}
string1 = "AG Edward"

string2 = "AG Edwards"

adist(x = string1, y = string2)
```

The <span class="func">adist</span> function uses generalized edit distance as the metric. 
This does things like calculate the number of characters that need to be inserted, deleted, or substituted to make a match. 

If we are merging, generalized edit distance might not give use the level of granularity that we need for minimizing.


Let's try out a few different strings below.

The next metric we'll look at is the Jaro-Winkler distance: [link](https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance) 
JW favors two strings with a shared prefix, and ranges from 0 (exact match) to 1 (no similarity).

```{r}
library(stringdist)

string3 = "A G Edwards"

stringdist(string1, string2, method = "jw")

stringdist(string2, string3, method = "jw")

stringdist(string1, string3, method = "jw")
```

And compare them to our standard edit distance:

```{r}
adist(c(string1, string2, string3))
```

We can see that we get a little more fine scoring with the Jaro-Winker distance.


Now let's take a look at the Jaccard distance: [link](https://en.wikipedia.org/wiki/Jaccard_index) 

Jaccard takes a set approach, and compares the two strings based on similar *n-grams*.

```{r}
stringdist(string1, string2, method = "jaccard")

stringdist(string2, string3, method = "jaccard")

stringdist(string1, string3, method = "jaccard")
```


You might be wondering why we need much granularity. 
Consider what happens between Safeway and Subway:

```{r}
stringdist("safeway", "subway", method = "soundex")

stringdist("safeway", "subway", method = "jaccard")

stringdist("safeway", "subway", method = "jw")

```

I think we can imagine the consequences of using metrics like soundex or Jaccard distance to join strings together.

So, is there a good time to use something like soundex: sure. 
If you find yourself needing to find any possible word matches.

## Fuzzy Joins


Let's use these files:

```{r, eval = TRUE}
library(data.table)

fuzzyJoinClients = fread("https://www3.nd.edu/~sberry5/data/fuzzyJoinClients.csv")

fuzzyJoinCompustat = fread("https://www3.nd.edu/~sberry5/data/fuzzyJoinCompustat.csv")

names(fuzzyJoinClients)
names(fuzzyJoinCompustat)

# because of the size of these data sets and how large fuzzy join results can be, we'll lok at a subset
fuzzyJoinClients = fuzzyJoinClients[1:1000,]
fuzzyJoinCompustat = fuzzyJoinCompustat[1:1000]

```

We are going to merge on "TIENAME" and "Company Name", but they need some work.

```{r, eval = TRUE}
fuzzyJoinClients$TIENAME = tolower(fuzzyJoinClients$TIENAME)

fuzzyJoinCompustat$`Company Name` = tolower(fuzzyJoinCompustat$`Company Name`)

head(fuzzyJoinClients)
head(fuzzyJoinCompustat)

```


Let's try to merge them normally:

```{r, eval = FALSE}
standardJoin = inner_join(fuzzyJoinClients, fuzzyJoinCompustat, 
                         by = c("TIENAME" = "Company Name"))
```

Not too good, right?

```{r, eval = FALSE}
fuzzyStuff = fuzzyjoin::stringdist_inner_join(fuzzyJoinClients, fuzzyJoinCompustat, 
                         by = c("TIENAME" = "Company Name"), 
                         max_dist = .5, method = "jw", 
                         distance_col = "stringDistance")
```


## Your turn
Spend some time doing fuzzy joins on these two data sets. 
Vary the join type, distance metric, and threshold. 

# Tips & Tricks 

## Row/Group Indices

When you are doing some type of data wrangling tasks (especially when things need grouped or merged), you might find a row or group index to be helpful.

```{r}
library(dplyr)

carsID = mtcars %>% 
  mutate(rowID = 1:nrow(mtcars),
    groupID = group_indices(.,cyl))

carsID
```


## Dates and Times

### lubridate

Another glorious thing that will happen to you is working with dates -- they tend to be a pain.

```{r}
Sys.Date()

format(Sys.Date(), "%m-%d-%Y")
```

And you get things like this:

```{r}
date1 = "12012018"

date2 = "20180112"

date3 = "12-01-2018"

date4 = "12/01/2018"
```

If you had to merge data based upon these dates, you would be in trouble.

You could, naturally, use some of the string cleaning stuff that we learned to tear them apart and then re-arrange them in a consistent manner.

```{r}
dateStrings = strsplit(date3, split = "-")

paste(dateStrings[[1]][3], 
      dateStrings[[1]][2], dateStrings[[1]][1], 
      sep = "-")
```


If we wanted to go down the path of that previous chunk, we would need to pass the whole thing into an lapply.

Or...we can just do this:

```{r}
library(lubridate)

mdy(date3)
```


There is some really great stuff in <span class="pack">lubridate</span>. 
For instance, if you need to get time intervals:

```{r}

exactAge = function(birthday, 
                    value = c("second", "minute", "hour", "day", 
                              "week", "month", "year")) {
  age = interval(ymd(birthday), ymd(Sys.Date()))  
  
  time_length(age, value)
}

```

Run that and give it your birthday in "YEAR-MO-DY" format. 
While it might be goofy at first glance, can we think of anything practical for it?


There is a similar package, <span class="pack">hms</span>, for dealing with time.


## Lists

Lists are just a part of life at this point. 
You will see lists of data frames and you will see columns within data frames that contain lists.

If you recall our previous look at JSON, you will see that there is a variable that actually contains a list.

We also saw our starwars example:

```{r}
glimpse(starwars)
```


There would be a few ways to tackle such an enterprise:

```{r}
movies = unique(unlist(starwars$films))

starwars = starwars %>% 
  mutate(revengeSith = ifelse(grepl(movies[grep("Sith", movies)], films), 
                              1, 0))
```



```{r}

library(tidyr)

data(starwars)

starwars = starwars %>% 
  unnest(films) %>% 
  mutate(id = 1:nrow(.)) %>% 
  spread(key = films, value = films) %>% 
  group_by(name) %>% 
  fill(14:20, .direction = "up") %>% 
  fill(14:20, .direction = "down") %>% 
  slice(1)


# OR 
data(starwars)  # back to original 
starwars = starwars %>% 
  unnest(films) %>%
  mutate(id = 1:nrow(.)) %>%
  pivot_wider(names_from = films, values_from = films) %>%
  group_by(name) %>% 
  fill(., 14:20, .direction = "up") %>%
  fill(., 14:20, .direction = "down") %>%
  slice(1) 

# OR
library(reshape2)
  
data(starwars)

# note that we had to remove vehicles and starships here.
# You can save them in a new object and cbind them back after
s.vehicles = starwars$vehicles
s.starships = starwars$starships
  
starwars = starwars %>% 
  select(-c(vehicles, starships)) %>%
    unnest(films) %>% 
    mutate(id = 1:nrow(.)) %>% 
    reshape2::dcast(.,...~films, value.var="films") %>%
    group_by(name) %>% 
    fill(12:18, .direction = "up") %>% 
    fill(12:18, .direction = "down") %>% 
    slice(1) 

starwars$vehicles = s.vehicles
starwars$starships = s.starships

```



Let's turn back to the ticket option JSON data:

```{r}
library(jsonlite)

jsonWhole = read_json("https://www3.nd.edu/~sberry5/data/optionsDataComplete.json", 
                      simplifyVector = TRUE)
```

What do we do with the list variable?

```{r}
spreadData = lapply(1:nrow(jsonWhole), function(x) {
  
  res = jsonWhole$teamTiers[[x]] %>% 
    reshape2::melt(.) %>% 
    reshape2::dcast(., value ~ tierShortName + variable) %>% 
    select(-value) %>% 
    summarize_all(sum, na.rm = TRUE)
  
  return(res)
}) %>% 
  data.table::rbindlist(., fill = TRUE)
```

And now, we can bind everything back up:

```{r}
jsonWhole = cbind(jsonWhole, spreadData) %>% 
  select(-teamTiers)
```



# Back To The Basics 

## Functions

I genuinely hope you learned a lot from our time together; however, if you only learn one thing, I hope that you feel empowered to write your own functions. 
For all of R's greatness, writing your own functions is what really makes it work so well. 

You might not feel like you can write a function -- we all feel that way at some point. 
You can!

Functions are simply objects that act upon other objects. 

This is a simple function:

```{r, eval = FALSE}

fido = seq(1, 10, by = 2)

sum(fido)
```


```{r, eval = FALSE}
meanFunction = function(x) {
  xLength = length(x)
  
  res = sum(x) / xLength
  
  return(res)
}
```

Specify what you are passing into the function (x above).

R already has a built-in mean() function, but now you know how easy it is to do such things.

When working on data manipulation tasks, functions become very useful because you will find yourself doing the same thing a lot. 

-- If you find yourself doing something more than twice, write a function!

## Your Turn

1.  Create a vector of something.

Something like the following:

```{r}
x = 1:5

# or...

x = c(1:4, 6)
```

2.  Tweak your vector in some fashion:

```{r}
x = x + 1
```


3.  Create a simple function to do something to your vector:  

Maybe try a series of math operations.

```{r}
testFunc = function(x) {
  res = sum(x * 3)
  return(res)
}
```


## Apply Family

We have seen a lot of different things over the last few hours together. 
The final bit of wisdom to pass along is the apply family. 
The apply family (lapply, sapply, mapply, etc.) allows you to pass a function over something like a list and then return something predictable. 

```{r}
testNames = c("Jack", "Jill", "Frank", "Steve", "Harry", "Lloyd")

sapply(testNames, function(x) paste(x, "went over the hill", sep = " "))
```

The sapply function will return a vector -- what do you think an lapply will return? mapply? Take a look at the documentation.

Now that is a bit of a goofy example. 
Since R is vectorized, we would have gotten the same result just by pasting our testNames vector to the string. 
But, a more realistic situation is as follows:



```{r}
starwarsShips = unique(unlist(starwars$starships))

shipRider = lapply(starwarsShips, function(x) {
  
  riders = starwars$name[which(grepl(x, starwars$starships))]
  
  res = data.frame(ship = x, 
                   riders = riders)
  
  return(res)
})
```


# Hackathon Prep

## Data sets

Where are they?

How do I find them? 

How do I download them? 

Possible sources of inspiration:

- [Kaggle](https://www.kaggle.com/datasets)
- [Data.gov](https://www.data.gov/open-gov/) 
- [Text data!](https://github.com/niderhoff/nlp-datasets) 
- [R packages that implement data sets](https://www.computerworld.com/article/3109890/these-r-packages-import-sports-weather-stock-data-and-more.html)
- [Possibly outdated list of R sports data (but a good place to start) packages](https://www.r-bloggers.com/sports-data-and-r-scope-for-a-thematic-rather-than-task-view-living-post/)


Just a note on the last two links above, if you are using data that is alreay loaded in an R package, that is (potentially) fine, but I'll expect that there will be extra work on the downstream tasks to make up for the fact that the data is already in R. 

## Your turn

Plan for tomorrow

- Groups: between 2-5 members, but if you have a compelling case for going solo, let me know
- Data: You'll need something to wrangle
- Objective: a 3-minute presentation on your data set, what you set out to learn from it, what you did learn, and how you went about learning it.
- Most important: If you can apply the methods from this week to some data that interests you, I will consider this week a success.

For your presentation you can present:

- Slides (Powerpoint OR pdf slides from an Rmd document)
- knitted Rmd document

Presentations should include:

- Team name
- Team members' names
- Data set introduction
- Wrangling performed (conceptual as well as tools used)
- Final insight (tables, plots, etc.) 

You should have your groups finalized by the end of class today. You don't necessarily need a final decision on your data (or team name), but that should be top priority for tomorrow morning.


